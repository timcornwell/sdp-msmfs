%rubber: module pdflatex

\documentclass[11pt,a4paper,variablewidth]{article}

\usepackage[sans]{tcc_doc} % SDP style file
\usepackage[english]{babel}
\usepackage{amssymb,amsmath} % for the math symbols
\usepackage{mdwlist}
\usepackage{geometry}
\usepackage{marginnote}
\usepackage{datetime}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{mathtools}
\usepackage{hhtensor}
\usepackage{color}
\usepackage{txfonts}
\usepackage{enumitem}


%\usepackage{stylefiles/fmtcount}
\usepackage{natbib}

\graphicspath{ {images/} }

\usepackage[boxruled,linesnumbered]{algorithm2e}
\usepackage{fmtcount}

\usepackage{array}
\newcolumntype{L}{>{\centering\arraybackslash}m{3cm}}


% TODO:
% 1. Check if all new symbols have been explained when used for the first
% time.
% 2. Check if all symbols are actually being used.
% 3. Check the symbol definitions: rates, numbers, etc. to use the same main letter
% 4. Is there a way to use proper referencing of applicable and reference
% documents?



%%%%%%%%% START OF USER SETTINGS %%%%%%%%%%%%%%%%%%

% Enter here some information needed to fill in the template Title to appear
% on the front pages (will be filled in via the \sdpfrontpage command)
\newcommand{\bigdoctitle}{Implementation of the Rau-Cornwell MSMFS algorithm \xspace}
% Title to go in the "Document Status Sheet" Document number
\newcommand{\docnr}{TCC-SDP-151123-2\xspace}
% Context
\newcommand{\context}{(SDP.PIP)}
% Revision
\newcommand{\revision}{3\xspace}
% Author(s)
\newcommand{\docauthor}{T.J.\ Cornwell\xspace}
% Lead author (goes in the footer)
\newcommand{\leadauthor}{T.J.\ Cornwell\xspace}
% Release date (YYYY-MM-DD)
\newcommand{\docudate}{\today\ \currenttime}
% Document classification
\newcommand{\classification}{Unrestricted}
% Status of the document (draft/final/etc.)
\newcommand{\docstatus}{Draft\xspace}

% The definitions below are used for the signature tables in the preamble of
% the document
\newcommand{\firstsigname}{T.J. Cornwell}
\newcommand{\firstsigdesignation}{Author}
\newcommand{\firstsigaffiliation}{TCC}

\newcommand{\secondsigname}{T.J. Cornwell}
\newcommand{\secondsigdesignation}{Lead Consultant}
\newcommand{\secondsigaffiliation}{TCC}

% Table with version numbers
\newcommand{\versiontable}{
  \begin{tabularx}{\textwidth}{|X|X|X|X|}
    \hline
    \bf{Version} & {\bf Date of issue} & {\bf Prepared by} & {\bf Comments}\\
    \hline
    0.3 & 27/04/2016 & T.J. Cornwell & Ready for review by Anna and Steve \\
    \hline
  \end{tabularx}
}

%%%%%%%%%%%%% END OF USER SETTINGS %%%%%%%%%%%%%%%%%%%

% Table with signatures
\newcommand{\signaturetable}[3]{
  \begin{tabularx}{\textwidth}{|X|X|X|}
    \hline
    Name & Designation & Affilitation\\
    \hline
    {#1} & {#2} & {#3}\\
    \hline
    Signature \& Date: & & \\
    & & \\
    & & \\
    \hline
  \end{tabularx}
}



% Table with affiliations
\newcommand{\organisationtable}{
  \begin{center}
    \sffamily{\bf ORGANISATION DETAILS}\end{center}
  \begin{table}[htb]
    \centering
    \begin{tabular}[htb]{|l|l|}
      \hline
      Name & Tim Cornwell Consulting\\
      \hline
    \end{tabular}
  \end{table}
}


%%%%%%%%%%%%%%%%%%%% START YOUR DOCUMENT HERE %%%%%%%%%%%%%%%%%

\newcommand{\subsubsubsection}[1]{\noindent{\bf{#1}}}

%%%% Please DO USE the symbol definitions listed below to preserve
%%%% consistency.

%%%% If you need a new symbol, please add it here. If really want to modify
%%%% one, do so, just take care to do a search-and-replace for the entire document
% Symbol definitions



\begin{document}

% load automatic pages
\tccfrontpage

\sdptableofcontents

% Add here the abbreviations used in your document
\sdplistofabbreviations
\begin{basedescript}{\desclabelstyle{\pushlabel}\desclabelwidth{6em}}
    \item[CDR] Critical Design Review \vspace{-0.2cm}
    \item[FFT] Fast Fourier Transform\vspace{-0.2cm}
    \item[FLOP] Floating Point Operations \vspace{-0.2cm}
    \item[FLOPS] Floating Point Operations per Second \vspace{-0.2cm}
    \item[FoV] Field of View\vspace{-0.2cm}
    \item[MS-MFS] Multi-Scale Multi-Frequency Synthesis\vspace{-0.2cm}
    \item[PSF] Point Spread Function \vspace{-0.2cm}
    \item[SDP] Scientific Data Processor\vspace{-0.2cm}
    \item[SKA] Square Kilometre Array\vspace{-0.2cm}
    \item[SKAO] SKA Organisation\vspace{-0.2cm}
%    \item[] \vspace{-0.2cm}
\end{basedescript} 

\newcommand{\nuno}{{\left(\frac{\nu}{\nu_0}\right)}}
\newcommand{\dnuno}{{\left(\frac{\nu-\nu_0}{\nu_0}\right)}}

\newcommand{\dg}{^\dag}
\newcommand{\X}{\vec{x}}
\newcommand{\Xd}{\vec{{x}^\dag}}
\newcommand{\B}{\vec{b}}
\newcommand{\Bd}{\vec{b^\dag}}
\newcommand{\V}{\vec{V}}
\newcommand{\Vd}{\vec{V^\dag}}
\newcommand{\A}{{\tens{A}{}}}
\newcommand{\Ad}{{\tens{A^\dag}{}}}
\newcommand{\F}{{\tens{F}{s}}}
\newcommand{\Fd}{{\tens{F^\dag}{}}}
\newcommand{\He}{{\tens{H}{}}}
\newcommand{\Sa}{{\tens{S}{}}}
\newcommand{\Sd}{{\tens{S^\dag}{}}}
\newcommand{\Sna}{\tens{{S_{\nu}}{}}}
\newcommand{\Snd}{\tens{{S_{\nu}^\dag}{}}}
\newcommand{\T}{{\tens{T}{}}}
\newcommand{\W}{{\tens{W}{}}}
\newcommand{\Wd}{{\tens{W^\dag}{}}}
\newcommand{\Pb}{{\vec{P}}}

%\newcommand{\Wim}{{\tens{W^{im}}}}
%\newcommand{\Wimd}{{\tens{{W^{im}}^\dag}}}
%\newcommand{\Wnt}{{\tens{W^{\rm {mfs}}_t}}}
%\newcommand{\Wntd}{{\tens{{W^{\rm {mfs}}_t}^\dag}}}
%\newcommand{\Wnp}{{\tens{W^{\rm mfs}_p}}}
%\newcommand{\Wnpd}{{\tens{{W^{\rm mfs}_p}^\dag}}}
%\newcommand{\Wnq}{{\tens{W^{\rm mfs}_q}}}
%\newcommand{\Wnqd}{{\tens{{W^{\rm {mfs}}_q}^\dag}}}
%\newcommand{\Wimn}{{\tens{W^{im}_{\nu}}}}
%\newcommand{\Wimnd}{{\tens{{W^{im}_{\nu}}^\dag}}}

\newcommand{\Wim}{{{\W^{\rm im}}}}
\newcommand{\Wimd}{{{{\W^{\rm im}}^\dag}}}
\newcommand{\Wnt}{{{\W^{\rm {mfs}}_t}}}
\newcommand{\Wntd}{{{{\W^{\rm {mfs}}_t}^\dag}}}
\newcommand{\Wnp}{{{\W^{\rm mfs}_p}}}
\newcommand{\Wnpd}{{{{\W^{\rm mfs}_p}^\dag}}}
\newcommand{\Wnq}{{{\W^{\rm mfs}_q}}}
\newcommand{\Wnqd}{{{{\W^{\rm {mfs}}_q}^\dag}}}
\newcommand{\Wimn}{{{\W^{\rm im}_{\nu}}}}
\newcommand{\Wimnd}{{{{\W^{\rm im}_{\nu}}^\dag}}}

\newcommand{\wnt}{{w_{\nu}^t}}
\newcommand{\wnq}{{w_{\nu}^q}}
\newcommand{\wntq}{{w_{\nu}^{t+q}}}
%\newcommand{\Wntn}{{\tens{w^{\rm mfs}_{t,\nu}}}}
%\newcommand{\Wntnd}{{\tens{{w^{\rm mfs}_{t,\nu}}^\dag}}}
%\newcommand{\Wnpn}{{\tens{W^{\rm mfs}_{p,\nu}}}}
%\newcommand{\Wnpnd}{{\tens{{W^{\rm mfs}_{p,\nu}}^\dag}}}

\newcommand{\pd}{{\partial}}
\newcommand{\mi}{{m_{I}}}
\newcommand{\R}{{R}}
\newcommand{\Rd}{{R^\dag}}
\newcommand{\I}{{\vec{I}}}

\newcommand{\Nt}{N_{\rm t}}
\newcommand{\Ns}{N_{\rm s}}
\newcommand{\Nc}{N_{\rm c}}


\sdplistoffigures

\sdplistoftables

% Add here the executive summary
\sdpsummary

Parallel versions of both variants of MSMFS exist. These work by distributing in time (CASA) and frequency (ASKAPsoft). Parallelisation of the Minor Cycle is not straightforward and consequently both CASA and ASKAPsoft currently use single-threaded inner loops. This is unlikely to be successful for SKA, and instead the Minor Cycle has to be parallelised inside one CI and perhaps additionally distributed over multiple CI's.

In light of this memo, the following recommendations are made concerning the need for MFS:

\begin{enumerate}
\item Perform simulations to explore the need for MSMFS in SKA. Currently an L1 requirement directs SDP to implement MSMFS. However there is no justification given for this very computationally demanding processing. Indeed the promised excellent UV coverage of the SKA telescopes makes it at least questionable, although arguing from the work of Urvashi [RD??] does indicate that with MFS, the dynamic range would be limited to $10^4$ for wide frequency span. Either CASA or ASKAPsoft could be used for the reconstructions.
\item Adding to the desire to see some more justification of the requirement, we note that the L1 requirements do not address the number of scales required, the number of Taylor terms, or the possibility of sub-banding (all of which appear in the SDP L2 requirements. We note three possible outcomes of the simulations: MFS can be ignored, MFS is required and MSMFS is sufficient, or MFS is needed and MFMFS is not sufficient. In the case of the latter outcome, investigation of other deconvolution techniques (e.g. [RD14]) would be required.
\item Assess the importance of the considerations in Section \ref{sec:other}.
\end{enumerate}

The following recommendations address the resource usage:
\begin{enumerate}[resume]
\item Implement both Image (CASA) and Visibility based (ASKAPsoft) calculation of the Taylor term images in the SDP Performance Model. The main reasons to choose one over the other are to do with the relative speed of gridding and FFTs. When it comes to implementation during construction, the costs of implementing both approaches should be minimal, and unimportant compared to the risk of implementing the wrong choice.
\item Update the SDP Performance Model to reflect the MSMFS memory usage:
\begin{equation}
M_{MSMFS} = (N_T (N_s + 1) + N_s) N_{pix}^2 
\end{equation}
\item Update the SDP Performance Model to reflect the MSMFS Flops:
\begin{equation}
Rflop_{MSMFSminor} = N_{minor} N_{pix}^2 N_s N_T	
\end{equation}
\item Prototype a multi-threaded Minor Cycle on one Compute Island. GPUMultiscaleCLEAN might be a good starting point. Do MS and then MSMFS. This can be done without implementing a major cycle.
\item Model and then, if promising, prototype a distributed Minor Cycle on multiple CI's where synchronisation occurs every iteration. Do MS and then MSMFS. This can be done without implementing a major cycle.\end{enumerate}

The following recommendations address wider issues:
\begin{enumerate}[resume]
\item The SKAO Science Team should be consulted about the impact of seams in the images or spectral cubes. These may occur both spatially (if the facets are deconvolved separately, or in frequency, because of the disjoint use of MSMFS in the different sub-bands. It seems questionable that these can be tolerated.

\item We should note that MSMFS was developed in a serial platform where computation was expensive and memory access cheap. In the SDP context, the processing is distributed and parallel, and computation is cheap and memory access expensive. Although SDP has no remit to develop new algorithms, it could encourage researchers to address this new context.
\end{enumerate}



\newpage

% Add to the table the list of applicable and reference documents (this is NOT
% meant for your usual bibiliography, only for SKA docs)
\sdpreferencedocs

\subsection*{Applicable Documents}

The following documents are applicable to the extent stated herein. In the
event of conflict between the contents of the applicable documents and this
document, \emph{the applicable documents} shall take precedence.

 \begin{center}
 \begin{tabularx}{\textwidth}{|l|X|}
     \hline
     \bf{Reference} & \bf{Reference}\\
     \bf{Number} & \\
     \hline
     {\bf [AD01]} & Dewdney, P. E. (2013). SKA1 System Baseline Design. SKA Office\\
     {\bf [AD02]} & McCool, R., Cornwell, T. (2013). Miscellaneous Corrections
     to the Baseline Design\\
     {\bf [AD03]} & SKA Phase 1 System (Level 1) Requirements Specification, T.Cornwell, SKA-OFF.SE.ARC-SKO-SRS-001\_2\\
     {\bf [AD04]} & PDR.01 SDP.ARCH document\\
     {\bf [AD05]} & SDP Costing spreadsheet\\
     {\bf [AD06]} & Cornwell, T.J. (2015). SKA1 Telescope Calibration
     Framework. SKA Office (draft version)\\
     {\bf [AD07]} & CSP--SDP ICD\\
     \hline
   \end{tabularx}
\end{center}

\clearpage
\subsection*{Reference Documents}

The following documents are referenced in this document. In the event of
conflict between the contents of the referenced documents and this document,
\emph{this document} shall take precedence.

 \begin{center}
 \begin{tabularx}{\textwidth}{|l|X|}
     \hline
     \bf{Reference} & \bf{Reference}\\
     \bf{Number} & \\
     \hline
   {\bf [RD01]} & SKA-TEL-SDP-0000027, R. Nijboer: Pipelines Element Subsystem Design\\
   {\bf [RD02]} & SKA-TEL-SDP-0000038, R. Bolton: High Priority Science Objectives: Performance Analysis\\
   {\bf [RD03]} & SKA-TEL-SDP-0000029, S. Salvini: Pipelines: Calibration\\
   {\bf [RD04]} & SKA-TEL-SDP-0000030, A. Scaife: Imaging Pipeline\\
   {\bf [RD05]} & \url{http://www.astron.nl/casacore/trunk/casacore/doc/notes/229.html}\\
   {\bf [RD06]} & Imager.cc C++ source, CASA source code SVN revision 30821, \url{https://svn.cv.nrao.edu/svn/casa/trunk}\\ 
   {\bf [RD07]} & Parameterized deconvolution for wide-band radio synthesis imaging, Urvashi Rao Venkata, 2010, PhD thesis\\
   {\bf [RD08]} & S. Bhatnagar, T. J. (2008). Correcting direction-dependent gains in the deconvolution of radio interferometric images. A\&A, 419-429\\
   {\bf [RD09]} & Rik Jongerius, S. W. (2014). An End-to-End Computing Model for the Square Kilometre Array. IEEE Computer, volume 47, number 9\\
   {\bf [RD10]} & SDP Element Concept. Paul Alexander, Chris Broekema, Simon Ratcliffe, Rosie Bolton, Bojan Nikolic, 2013, SDP-PROP-DR-001-1 (part of SKA SDP Consortium proposal)\\
   {\bf [RD11]} & Cornwell, T. J. (2008). Multi-Scale CLEAN deconvolution of radio synthesis images. IEEE Journal of Selected Topics in Sig. Proc., 2, 793–801.\\
   {\bf [RD12]} & Conway, J. E., Cornwell, T. J., and Wilkinson, P. N. (1990). Multi-Frequency Synthesis - a New Technique in Radio Interferometric Imaging. Monthly Notices of the Royal Astronomical Society, 246, 490.\\
   {\bf [RD13]} & http://www.aanda.org/component/citedby/?task=crossref\&doi=10.1051/0004-6361/201117104 \\  
   {\bf [RD14]} & Junklewitz, H., Bell, M. R., and Ensslin, T. (2015). A new approach to multifrequency synthesis in radio interferometry. Astronomy \& Astrophysics, 581, A59. http://doi.org/10.1051/0004-6361/201423465 \\
   {\bf [RD15]} & Cornwell, T.J. (2016) Extension of the SDP performance model for cross data-island connectivity, TCC-SDP-151123-1-1 \\
	{\bf [RD16]} & Rau, U., \& Cornwell, T. J. (2011, June 14). A multi-scale multi-frequency deconvolution algorithm for synthesis imaging in radio interferometry. arXiv.org. EDP Sciences. http://doi.org/10.1051/0004-6361/201117104   \\
	{\bf [RD17]} & Bhatnagar, S., Rau, U., \& Golap, K. (2013). Wide-field wide-band Interferometric Imaging: The WB A-Projection and Hybrid Algorithms. The Astrophysical Journal, 770(2), 91. http://doi.org/10.1088/0004-637X/770/2/91 \\
	\hline
 \end{tabularx}
\end{center}

\clearpage
\section{Purpose of the document}


The purpose of this document is to describe the Multi-Scale MultiFrequency Synthesis algorithm, the variant implementations in CASA and ASKAPsoft, and the scaling for insertion in the SDP Performance Model. We conclude with some recommendations.

\section{Scope of the document}

The scope includes only the published Multi-Scale, Multi-Frequency algorithm, existing implementations, and inclusion in the SDP processing pipelines. No other MFS algorithms are explored.

\section{Background}

The imaging performance of a radio synthesis telescope is related to the uv coverage. The uv coverage is dependent on the observing wavelength so diversity in uv can be obtained by observing over a range of frequencies [RD12]. This Multi-Frequency Synthesis (MFS) only works for radio sources in which broadband emission is present, giving a way to relate measurements at different frequencies. There have been multiple attempts at an MFS algorithm (e.g. [RD12]). MFS is usually most important for sources having extended emission. Hence multi-scale algorithms are favoured.

The Multi-Scale, Multi-Frequency Synthesis (MS-MFS) algorithm was developed by Urvashi [RD07], melding together the concepts from multi-scale clean [RD11] and multi-frequency synthesis e.g. [RD12], with the goal of improving the reconstruction of sky brightness from radio interferometric data. The explicit model used for the sky brightness is a collection of blobs of varying scale sizes and strengths, each with spectral behaviour described by a power law expanded into a Taylor series. It has been used in JVLA, ALMA, and ATCA observations [RD13].

The algorithm is an elaboration of the Multiscale CLEAN [RD11]. It consists of two parts:
\begin{description}
\item[Major cycle] The image residuals for the current model are calculated by Fourier transform of the images constituting the power law expansion and degridding to obtain the predicted visibility, subtraction from the observed visibility, then gridding, and Fourier transformation to the image plane. There are two ways of performing this cycle depending on whether the Taylor series is calculated in image or uv space. Typically 5 - 10 major cycles are required.
\item[Minor cycle] The minor cycle is a greedy algorithm which identifies the dominant candidate scale and removes that using the appropriate PSF centered on that component. The minor cycle repeats this until convergence. Typically hundreds or thousands of iterations are required.
\end{description}

A canonical major/minor cycle algorithm is shown in Figure \ref{fig:majorminor}. The two functions Predict and MakeImage are sub-pipelines. ASKAPSoft and CASA both follow this form but with different ways of performing Predict (Figures \ref{fig:predictuv} and \ref{fig:predictimage}) and MakeImage (Figures \ref{fig:makeimageuv} and \ref{fig:makeimageimage})

\begin{figure}[htb]
  \centering
  \includegraphics[width=\textwidth]{./MSMFS_MajorMinor.pdf}
  \caption{Structure of Major/Minor cycle algorithm}
  \label{fig:majorminor}
\end{figure}

The major cycle returns to the visibility data each iteration, whereas the minor cycle is entirely image-based.

MSMFS is relatively high in complexity because the usual CLEAN process is coupled over both scale (MSClean) and frequency or Taylor terms (MFS). The minor cycle must conduct a search in scale and Taylor term for each peak search. The major cycle requires calculation of the residual Taylor terms, which implies gridding and degridding all relevant frequency information. Memory use is high since a large number of images must be kept and updated as the iteration proceeds.

\clearpage

\section{Is MFS needed?}
\label{sec:mfsneeded}

There is an L1 requirement [AD03], $SKA1-SYS\_REQ-2324$ specifying that MSMFS must be used for continuum imaging (see Table\ref{tab:L1}).

\begin{table}[htp]
\begin{tabular}{|c|L|c|c|c|}
\hline
ID & Requirement & Status & Parent Requirement & Verification \\
\hline$SKA1-SYS\_REQ-2324$ &Multi-frequency synthesis imaging. All imaging shall construct and make use of frequency dependent image models over the entire observed bandwidth. & Accepted & Reference & Demonstration \\
\hline 
\end{tabular}	
\caption{Relevant L1 requirement}\label{tab:L1}	
\end{table}

This is reflected in the L2 requirements shown in Table \ref{tab:L2}.
\begin{table}[htp]
\begin{center}
\begin{tabular}{|L|L|L|L|L|}
\hline
\multicolumn{2}{|c|}{Function}&\multicolumn{3}{c|}{Satisfies requirement}\\
\hline
Number & 	Name & 	Number	& Name	& Description \\
\hline
F1.9 & Calibrate and Image & $SDP\_REQ-390$	&Multi-frequency synthesis
  imaging	& The SDP shall construct and make
  use of frequency-dependent image models over the entire observed bandwidth. \\
\hline
F1.9 & Calibrate and Image & $SDP\_REQ-676$	& Continuum imaging deconvolution
  scales &	While performing continuum
  imaging the SDP shall deconvolve using a maximum number of 10 (TBC) scales.\\
\hline
F1.9 & Calibrate and Image & $SDP\_REQ-677$	& Continuum imaging deconvolution
  Taylor terms &	While performing continuum
  imaging the SDP shall deconvolve using a maximum number of 5 (TBC) Taylor
  terms.\\
\hline
F1.9 & Calibrate and Image & $SDP\_REQ-678$	& Continuum imaging deconvolution
  by sub-band	& While performing continuum
  imaging the SDP shall deconvolve by sub-band (TBC).\\\hline 
\end{tabular}
\caption{Relevant L2 requirements}	\label{tab:L2}
\end{center}
\end{table}

The last three L2 requirements, $SDP\_REQ-676$, $SDP\_REQ-677$, $SDP\_REQ-678$, are an attempt to give some constraints to $SKA1-SYS\_REQ-2324$. However, they beg the same question as the original L1 requirement: is MSMFS needed to meet the scientific goals? If so, how many scales, Taylor terms, and sub-bands are required? In addition, there is also a potentially missing requirement concerning the connection between the models for different sub-bands - is there allowed to be a seam in the continuum-subtracted spectral line cube at the transitions between sub-bands?

Finally we could ask is there a superior algorithm already published? (see e.g. [RD14]). The degree of tuning required for MSMFS (number of scales and number of Taylor terms) is acceptable in a hands-on data processing scenario but may be not acceptable for a general purpose pipeline.

Some caution is advised in advocating that any form of MFS is not needed. Clearly ALMA and JVLA, which also have relatively good uv coverage, have benefited from the use of MSMFS. Furthermore, although the uv-coverage of SKA1-LOW and SKA1-MID is excellent after a long observation, there will inevitably be pressure to observe with shorter observation times. We should remember than the VLA was supposed to take 8 hours to image every field. With the advent of CLEAN and self-calibration, it was known even in the early eighties that 400 sources could be imaged in a day.

Urvashi has discussed the use of MSMFS for the JVLA (section 8.4.2.1 of [RD??]. With regard to just ignoring the effect of spectral index variations, she says:

\begin{quotation}
Dynamic-range limits when source spectra are ignored : If continuum imaging is done with only MFS gridding and source spectra are ignored, spectral structure will masquerade as spurious spatial structure. These errors will affect regions of the image both on-source and off-source and their magnitudes depend on the available uv-coverage, the frequency range being covered, the choice of reference frequency, and the intensity and spectral index of the source. A rough rule of thumb for an EVLA-type uv-coverages (see section 6.2.4.2) is that for a point source of with spectral index α = −1.0 measured between 1 and 2 GHz, the peak error obtained if the spectrum is ignored is at a dynamic range of $ < 10^3$. Note that when all sources in the observed region of the sky have similar spectral indices, these errors can be reduced by dividing out an average spectral index (one single number over the entire sky) from the visibilities before imaging the\end{quotation}

If we suppose that the SKA PSF is ten times better than that of the JVLA (an over estimate since the RMS sidelobe level goes only as the inverse of the number of antennas), the dynamic range limitation for SKA1-LOW and SKA1-MID still appears at about $10^4$, which is clearly insufficient. Furthermore, the primary beam will vary across the frequency span, and this will lead to spurious structure if spectral effects are ignored (cf Urvashi). The introduction of sub-bands does ameliorate these problems to some degree but then the continuum structure model is only defined in pieces that are not necessarily consistent at the edges.

There is no mechanism to address these questions beyond simulations. Arguing from uv coverage metrics such as the UVGAP only helps in a relative sense.


\clearpage

\section{Overview of MSMFS}
\label{sec:overview}

\subsection{Mathematical description}

In the Multi-Scale CLEAN [RD11], the sky is modelled as a set of blobs. Performing this decomposition using a gradient search algorithm is very demanding of resources. Instead, in MSCLEAN, a greedy algorithm obtained by generalising the CLEAN algorithm is used. The greedy algorithm locates the amplitude, scale and location of the blob by a straightforward search in the set of residual images, each smoothed with the appropriate blob. For each minor cycle this produces an amplitude, location, and scale. The smoothed residual images and model images are updated, and iteration proceeds.

\begin{equation}
\vec{I}^{model} = \sum_{s=0}^{N_s-1}  \vec{I}^{shp}_{s} \star \vec{I}^{sky,\delta}_s
\label{Eq:ms_model}
\end{equation}

where $N_s$ is the number of spatial scales used to construct the image, and
$\vec{I}^{sky,\delta}_{s}$ represents a collection of $\delta$-functions that describe the locations
and integrated amplitudes of flux components of scale $s$ in the image. $\vec{I}^{shp}_s$ is a tapered truncated parabola of width proportional to $s$.
The symbol $\star$ denotes convolution. 

The MSMFS [RD07] algorithm decomposes the image into a set of $N_s$ blobs each with $N_t$ Taylor terms. The following description is drawn from [RD07]

\begin{eqnarray}
\label{eqn:mf_model}
\vec{I}^{model}_{\nu} = \sum_{t=0}^{N_t-1} \wnt \vec{I}^{sky}_{t} ~~~\mathrm{where}~~~ \wnt&=&\dnuno^t 
\end{eqnarray}

where $N_t$ is the order of the Taylor series expansion, and 
the $I^m_t$ represent multi-scale Taylor coefficient images.

The image flux model at each frequency can be written as a linear sum of  
coefficient images at different spatial scales. 
\begin{equation}
\vec{I}^{model}_{\nu} = \sum_{t=0}^{N_t} \sum_{s=0}^{N_s} \wnt \left[ \vec{I}^{shp}_s \star \vec{I}^{sky}_\frac{s}{t}\right] ~~~~\mathrm{where}~~~\wnt = \dnuno^t 
\label{eqn:msmf_model}
\end{equation}

Here, $N_s$ is the number of discrete spatial scales used to represent the image and  
$N_t$ is the order of the series expansion of the spectrum. $\vec{I}^{sky}_\frac{s}{t}$ represents 
a collection of $\delta$-functions that describe the locations
and integrated amplitudes of flux components of scale $s$ in the image of the $t^{th}$ series 
coefficient. 

The visibility function corresponding to \ref{eqn:msmf_model} is:
\begin{eqnarray}
\vec{V}^{\rm obs}_{\nu} &=& [\Sna][\F]\vec{I}^{\rm m}_{\nu}
= \sum_{t=0}^{\Nt } \sum_{s=0}^{\Ns } \wnt [\Sna][\T_s][\F] \vec{I}^{\rm sky}_{s\atop t}
\label{eqn:msmfs_meqn}
\end{eqnarray}

$\vec{V}^{\rm obs}_{\nu}$ is a vector of $n\times 1$ visibilities
measured at frequency $\nu$.
$w_{\nu}$ are Taylor-weights (shown in Eqn.\ref{Eq:msmf_model}).
$[\Sna]$ is an $n\times m$ projection operator that represents the 
spatial-frequency sampling function for frequency $\nu$. 
The image-domain convolution of model $\vec{I}^{\rm sky}_{s\atop t}$ with
 $\I^{\rm shp}_s$ is written as a spatial-frequency-domain multiplication.
$ \vec{I}^{\rm shp}_s \star \vec{I}^{\rm sky}_{s\atop t} = [\Fd][\T_s][\F] \vec{I}^{\rm sky}_{s\atop t}$
where $[\T_s]_{m\times m} = diag([\F] \vec{I}^{\rm shp}_s)$ is a spatial-frequency
taper function.  All images are vectors of shape $m\times 1$.

The normal equations 
for the system described in Eqn. \ref{Eq:msmfs_meqn}
can be written in block matrix form, with each block-row 
(for scale size $s$, and Taylor term $t$) given by
\begin{eqnarray}
\label{Eq:msmfs_neqn_1}
\sum_{p=0}^{\Ns -1}\sum_{q=0}^{\Nt -1} \left[\He_{{s,p}\atop{t,q}}\right] \vec{I}^{\rm sky}_{{p}\atop{q}} &=& \vec{I}^{\rm dirty}_{{s}\atop{t}}~~~  \forall~ s \in [0,\Ns -1], t\in[0,\Nt -1]
\end{eqnarray}
Here, each $\left[\He_{{s,p}\atop{t,q}} \right]$ is an $m\times m$ block of the 
Hessian matrix, and $\vec{I}^{\rm dirty}_{{s}\atop{t}}$ is one of $\Ns  \Nt $ dirty images.
\begin{eqnarray}
\left[\He_{{s,p}\atop{t,q}} \right] &=& \left[\A_{{s}\atop{t}}^{\dag}\right][\Wim] \left[\A_{{p}\atop{q}}\right] \\
 &=&    [\Fd \T_s  \Sd \Wntd ]  [\Wim]  [\W^{\rm mfs}_q \Sa \T_p \F] \\
 &=&    [\Fd \T_s \F] [\Fd  \Sd \Wntd  \Wim  \W^{\rm mfs}_q \Sa  \F] [\Fd \T_p \F]\\
% &=&    [\Fd \T_s \F] [\He^{\rm mfs}_{t,q}] [\Fd \T_p \F]
 &=& [\Fd \T_s \F] \left\{  \sum_{\nu} \wntq [\Fd\Snd\Wimn\Sna\F] \right\} [\Fd \T_p \F] \\
 &=& [\Fd \T_s \F] \left\{  \sum_{\nu} \wntq [\He_{\nu}\} \right\} [\Fd \T_p \F] 
\end{eqnarray}

$[\Wim]$ is a diagonal matrix of data-weights (and imaging-weights) and  
$[\W^{\rm mfs}_t]$ is a diagonal matrix containing Taylor-weights $\wnt$.
$[\He_{\nu}] =  [\Fd\Snd\Wimn\Sna\F]$ is the Hessian matrix formed using only one
 frequency channel, and
is a convolution operator containing a shifted version of the single-frequency 
point-spread-function $\I^{\rm psf}_{\nu} = diag[\Fd \Sd \Wimn \Sa]$ in each row 
(see appendix \ref{App:normal} for details).
$[\Fd \T_s\F]$ and $[\Fd\T_p\F]$ are also convolution operators 
with $\I^{\rm shp}_s$ and $\I^{\rm shp}_p$ as their kernels. 
The process of convolution is associative and commutative, and 
therefore, $\left[\He_{{s,p}\atop{t,q}}\right]$  is also a convolution operator 
whose kernel is given by 
\begin{equation}
\label{Eq:msmfs_neqn_2.5}
\vec{I}^{\rm psf}_{{s,p}\atop{t,q}} = \I^{\rm shp}_s  \star \left\{ \sum_{\nu} \wntq \vec{I}^{\rm psf}_{\nu} \right\} \star \I^{\rm shp}_p 
%&=& \I^{\rm shp}_s \star I^{\rm psf}_{t,q} \star \I^{\rm shp}_p
\end{equation}

\noindent The dirty images on the RHS of Eqn.\ref{Eq:msmfs_neqn_1} can be written as follows.
\begin{eqnarray}
\label{Eq:msmfs_neqn_3}
\vec{I}^{\rm dirty}_{{s}\atop{t}}  &=&  \left[\A_{{s}\atop{t}}^{\dag}\right][\Wim]  \vec{V}^{\rm obs}\\
&=& [\Fd \T_s \Sd\Wntd\Wim] \vec{V}^{\rm obs} \\
&=& [\Fd \T_s \F][\Fd\Sd\Wntd\Wim] \vec{V}^{\rm obs} \\
&=& [\Fd \T_s \F] \left\{  \sum_{\nu} \wnt [\Fd\Snd\Wimn] \vec{V}_{\nu}^{\rm obs}  \right\} \\
&=& \I^{\rm shp}_s \star \left\{\sum_{\nu} \wnt \vec{I}^{\rm dirty}_{\nu}  \right\} 
%&=& [\Fd \T_s \F] \vec{I}^{\rm dirty}_t = \I^{\rm shp}_s \star \vec{I}^{\rm dirty}_t\\
\label{Eq:msmfs_neqn_3a}
%\vec{I}^{\rm dirty}_{t}  &=& [\Fd\Sd\Wntd\Wim] \vec{V}^{corr}\\
% &=& \sum_{\nu} \wnt [\Fd\Snd\Wimn] \vec{V}_{\nu}^{corr} = \sum_{\nu} \wnt \vec{I}^{\rm dirty}_{\nu}\\
%\label{Eq:specPSF}
%\vec{I}^{\rm psf}_{t,q}&=& \sum_{\nu} \wntq [\Fd\Snd\Wimn] \vec{1} = \sum_{\nu} \wntq \vec{I}^{\rm psf}_{\nu}
\end{eqnarray}
where ${\I}_{\nu}^{\rm dirty} = [\Fd \Snd \Wimn] \vec{V}^{\rm obs}_{\nu} $ is the dirty
image formed by direct Fourier inversion of weighted visibilities from one frequency channel.


When all scales and Taylor terms are combined, 
the full Hessian matrix contains
$\Nt  \Ns  \times \Nt  \Ns $ blocks each of size $m\times m$, 
and $\Nt $ Taylor coefficient images each of size $m\times 1$, 
for all $\Ns $ spatial scales.

The normal equations in block matrix form for the example 
in Eqn.\ref{meqn_msmfs_math} for $\Nt =3, \Ns =2$ is shown
in Eqn.\ref{Eq:msmfs_neqn_matrix}.
The Hessian matrix consists of $\Ns \times \Ns =2\times 2$ blocks 
(the four quandrants of the matrix), each for one pair of spatial scale $s,p$ (the upper indices).
Within each quadrant, the $\Nt \times \Nt  = 3\times 3$
matrices correspond to various pairs of $t,q$ (Taylor coefficient indices; the lower indices).
This layout shows how the multi-scale and multi-frequency aspects of
this imaging problem are combined and illustrates the 
dependencies between the spatial and spectral basis functions.

\begin{equation}\small
\left[\begin{array}{llllll} 
\noalign{\medskip}
   \left[\He_{{ 0, 0}\atop{ 0, 0}}\right] & \left[\He_{{ 0, 0}\atop{ 0, 1}}\right] & \left[\He_{{ 0, 0}\atop{ 0, 2}}\right] & \left[\He_{{ 0, 1}\atop{ 0, 0}}\right] & \left[\He_{{ 0, 1}\atop{ 0, 1}}\right] & \left[\He_{{ 0, 1}\atop{ 0, 2}}\right] \\  
\noalign{\medskip}
   \left[\He_{{ 0, 0}\atop{ 1, 0}} \right] & \left[\He_{{ 0, 0}\atop{ 1, 1}}\right] & \left[\He_{{ 0, 0}\atop{ 1, 2}}\right] & \left[\He_{{ 0, 1}\atop{ 1, 0}}\right] & \left[\He_{{ 0, 1}\atop{ 1, 1}}\right] & \left[\He_{{ 0, 1}\atop{ 1, 2}}\right] \\  
\noalign{\medskip}
   \left[\He_{{ 0, 0}\atop{ 2, 0}} \right] & \left[\He_{{ 0, 0}\atop{ 2, 1}}\right] & \left[\He_{{ 0, 0}\atop{ 2, 2}}\right] & \left[\He_{{ 0, 1}\atop{ 2, 0}}\right] & \left[\He_{{ 0, 1}\atop{ 2, 1}}\right] & \left[\He_{{ 0, 1}\atop{ 2, 2}}\right] \\  
\noalign{\medskip}
%   \hline
\noalign{\medskip}
   \left[\He_{{ 1, 0}\atop{ 0, 0}} \right] & \left[\He_{{ 1, 0}\atop{ 0, 1}}\right] & \left[\He_{{ 1, 0}\atop{ 0, 2}}\right] & \left[\He_{{ 1, 1}\atop{ 0, 0}}\right] & \left[\He_{{ 1, 1}\atop{ 0, 1}}\right] & \left[\He_{{ 1, 1}\atop{ 0, 2}}\right] \\  
\noalign{\medskip}
   \left[\He_{{ 1, 0}\atop{ 1, 0}} \right] & \left[\He_{{ 1, 0}\atop{ 1, 1}}\right] & \left[\He_{{ 1, 0}\atop{ 1, 2}}\right] & \left[\He_{{ 1, 1}\atop{ 1, 0}}\right] & \left[\He_{{ 1, 1}\atop{ 1, 1}}\right] & \left[\He_{{ 1, 1}\atop{ 1, 2}}\right] \\  
\noalign{\medskip}
   \left[\He_{{ 1, 0}\atop{ 2, 0}} \right] & \left[\He_{{ 1, 0}\atop{ 2, 1}}\right] & \left[\He_{{ 1, 0}\atop{ 2, 2}}\right] & \left[\He_{{ 1, 1}\atop{ 2, 0}}\right] & \left[\He_{{ 1, 1}\atop{ 2, 1}}\right] & \left[\He_{{ 1, 1}\atop{ 2, 2}}\right] \\  
\noalign{\medskip}
   \end{array} \right]
\left[\begin{array}{l} 
\noalign{\medskip}
		       \vec{I}^{\rm sky}_{{ 0}\atop{ 0}} \\ 
\noalign{\medskip}
                       \vec{I}^{\rm sky}_{{ 0}\atop{ 1}}\\ 
\noalign{\medskip}
		       \vec{I}^{\rm sky}_{{ 0}\atop{ 2}}\\ 
\noalign{\medskip}
%\hline
\noalign{\medskip}
		       \vec{I}^{\rm sky}_{{ 1}\atop{ 0}} \\ 
\noalign{\medskip}
		       \vec{I}^{\rm sky}_{{ 1}\atop{ 1}}\\ 
\noalign{\medskip}
		       \vec{I}^{\rm sky}_{{ 1}\atop{ 2}}\\
\noalign{\medskip}
			       \end{array}\right] =
\left[\begin{array}{l} 
\noalign{\medskip}
                       \vec{I}^{\rm dirty}_{{ 0}\atop{ 0}}  \\ 
\noalign{\medskip}
                       \vec{I}^{\rm dirty}_{{ 0}\atop{ 1}} \\ 
\noalign{\medskip}
		       \vec{I}^{\rm dirty}_{{ 0}\atop{ 2}}\\ 
\noalign{\medskip}
%\hline
\noalign{\medskip}
		       \vec{I}^{\rm dirty}_{{ 1}\atop{ 0}} \\ 
\noalign{\medskip}
		       \vec{I}^{\rm dirty}_{{ 1}\atop{ 1}} \\ 
\noalign{\medskip}
		       \vec{I}^{\rm dirty}_{{ 1}\atop{ 2}} \\
\noalign{\medskip}
			       \end{array}\right] 
\label{Eq:msmfs_neqn_matrix}
\end{equation}

This is the system of equations to be solved.
% to obtain estimates of the model parameters $I^{\rm sky}_{p\atop q}$.
The spatial-frequency sampling  of a real interferometer is always incomplete 
($[\Sa]$ is rank-deficient).
Therefore, each Hessian block, and the entire Hessian matrix is singular, and an exact inverse
does not exist\footnote
{Even if $[\He]$ were invertible, it is impractical to evaluate and invert the full Hessian
(each row of each Hessian block represents an image).
}. An accurate reconstruction can be obtained only via successive approximation
(iterative numerical optimization).
 
However, the Hessian is still useful since some of the diagonal terms can used to decouple the pixels in Taylor term space as well as possible. In practice, the Hessian (for each scale) for the peak of the PSF in Taylor term space is of modest size and can be inverted and used. The greedy algorithm then locates the scale and location in the reference-frequency image (as convolved with the set of scales). For each minor cycle this produces a location, scale, and values for all Taylor terms. The residual images and model images are updated, and iteration proceeds. The actual algorithm is shown in Algorithm \ref{algo:CASA} (CASA form) and Algorithm \ref{algo:ASKAP} (ASKAP form).

In summary, MSMFS decouples Taylor terms using the Hessian in Taylor-space evaluated at the peak of the PSF, and uses a greedy CLEAN-like algorithm to decouple in scale and sky position. The scales can be decoupled by an orthogonalisation process prior to deconvolution but the resulting images tend to have non-physical regions of negative brightness.



\clearpage
\section{CASA and ASKAPsoft implementations}

The MS-MFS algorithm as implemented in CASA shown in Algorithm \ref{algo:CASA}. The ASKAPsoft version is shown in Algorithm \ref{algo:ASKAP} with the variant lines in red.

We can relate these back to the graphical form Figure \ref{fig:majorminor} by introducing variant sub pipelines for Predict and MakeImage. These are graphically shown in Figures \ref{fig:predictuv} to \ref{fig:makeimageimage}: 

\begin{figure}[htb]
  \centering
  \includegraphics[width=\textwidth]{./MSMFS_Predict_UV.pdf}
  \caption{Structure of UV-weighting Predict, as used in ASKAPsoft. }
  \label{fig:predictuv}
\end{figure}

\begin{figure}[htb]
  \centering
  \includegraphics[width=\textwidth]{./MSMFS_MakeImage_UV.pdf}
  \caption{Structure of UV-weighting MakeImage, as used in ASKAPsoft. Note that the three loops (denoted by the rectangle with curved ends) can be permutated at will.}
  \label{fig:predictimage}
\end{figure}


\clearpage

\begin{algorithm}
\scriptsize
  \SetLine
  \linesnumbered
  \dontprintsemicolon
%  \SetKwRepeat{Repeat}{Repeat}{Until}
%  \SetKwFor{ForEach}{ForEach}{Do}{End}
%\KwData{ $\vec{V}^{corr}_{\nu}, \vec{I}^{\rm shp}_s~\forall~s\in\{0,\Ns $-$1\}, ~ [\Sna]~ \forall \nu$ }
%\KwResult{ $\vec{I}^{\rm psf}_{{sp}\atop{tq}},[{H^{\rm peak}_s}], \vec{I}^m_{\nu_0}, \vec{I}^{\alpha}, \vec{I}^{\beta}$ }
  \KwData{calibrated visibilities : $\vec{V}^{\rm obs}_{\nu}~~\forall \nu$}
  \KwData{$uv$-sampling function and weights : $[{\Sa}_{\nu}], [\Wimn]$}
  \KwData{input : number of Taylor-terms $\Nt $, number of scales $\Ns $}
  \KwData{input : image noise threshold, $\sigma_{\rm thr}$, loop gain $g$}
  \KwData{input : scale basis functions : $\I^{\rm shp}_s ~ \forall s\in\{0,\Ns -1\}$}
  \KwData{input : reference frequency $\nu_0$ to compute $w_{\nu}=\dnuno$}
  \KwResult{model coefficient images : $\I^{\rm m}_{t}~ \forall t\in\{0,\Nt -1\}$}
  \KwResult{intensity, spectral index and curvature : $\I^{\rm m}_{\nuup_0},\I^{\rm m}_{\alphaup},\I^{\rm m}_{\betaup}$}
 
%{Compute the dirty image $\vec{I}^{\rm dirty}$ and psf $\vec{I}^{\rm psf}$}\;
  \For{ $t \in \{0,\Nt -1\}, q \in \{t,\Nt -1\}$}
  {
        { Compute the spectral Hessian kernel } $\vec{I}^{\rm psf}_{tq} = \sum_{\nu} \wntq \vec{I}^{\rm psf}_{\nu}$\;
        \For{ $s \in \{0,\Ns -1\}, p \in \{s,\Ns -1\}$}
	{
		{Compute scale-spectral kernels} $\vec{I}^{\rm psf}_{{sp}\atop{tq}} = \vec{I}^{\rm shp}_s \star \vec{I}^{\rm shp}_p \star \vec{I}^{\rm psf}_{tq} $\;
	}
  }
  \For { $s \in \{0,\Ns -1\}$}
  {
     Construct scale-dependent Taylor space Hessian $[{\He^{\rm peak}_s}]$ from $mid(\I^{\rm psf}_{{s,s}\atop{t,q}})$ and compute $[{\He^{\rm peak}_s}^{-1}]$\;
  }
%%%%%%%%%%%%%%%%%%%%%%
%%%\vspace{0.5cm}
%%  \caption[MS-MFS CLEAN : Pre-Deconvolution Setup]
%%          {MS-MFS CLEAN : Pre-Deconvolution Setup}
%%\end{algorithm}
%%%\newpage
%%
%%\begin{algorithm}[\He]
%%  \SetLine
%%  \linesnumbered
%%  \dontprintsemicolon
%%%%%%%%%%%%%%%%%%%%%%%  
%%\KwData{ $\vec{V}^{corr}_{\nu}, \vec{I}^{\rm shp}_s, \vec{I}^{\rm psf}_{{sp}\atop{tq}},[{H^{\rm peak}_s}]~~~\forall~~s \in \{0,\Ns -1\}, p \in \{s,\Ns -1\}, \sigma_{thr}$ }
%%\KwResult{$I^{\rm m}_{q}~ \forall q \in \{0,\Nt -1\}$}
%%%%%%%%%%%%%%%%%%%%%  
  Initialize the model $\vec{I}^{\rm m}_t$ for all $t \in \{0,\Nt -1\}$\; % and compute $f_{sidelobe}$ \;
%  \vspace{0.5cm} 
  \Repeat (\tcc*[f]{Major Cycle}) { Peak residual in $\vec{I}^{\rm res}_0 < \sigma_{\rm thr}$ }
  {
    \For{$t \in \{0,\Nt $-$1\}$}
    {
      Compute $\vec{I}^{\rm res}_t = \sum_{\nu} \wnt \vec{I}^{\rm res}_{\nu}$ from frequency-weighted residual images $\I^{\rm res}_{\nu}$\;
      \For{$s \in \{0,\Ns $-$1\}$}
      {
	    Convolve with $s^{th}$ scale-function $\vec{I}^{\rm res}_{{s}\atop{t}} = \vec{I}^{\rm shp}_s \star \vec{I}^{\rm res}_t$
      }
    }
    Calculate minor-cycle threshold $f_{\rm limit}$ from $\vec{I}^{\rm res}_{{0}\atop{0}}$\;
%  \vspace{0.5cm} 
    \Repeat (\tcc*[f]{Minor Cycle}){ Peak residual in $\vec{I}^{\rm res}_{{0}\atop{0}} < f_{\rm limit} $ } 
    {
%     Compute $I^{\rm m}_q~\forall q\in \{0.\Nt -1\}$ and update $\vec{I}^{\rm res}_{{s},{t}}~\forall s,t$ (Algorithm \vref{MSMFS_2})\;
     \For{$s \in \{0,\Ns $-$1\}$}
     {
%      \uIf{Peak of $\vec{I}^{\rm res}_{s,0} > 10~\sigma_{thr} $}
%      {
       \ForEach{pixel}
       {
          Construct $\I^{\rm rhs}_s$, an $\Nt \times 1$ vector from $\I^{\rm res}_{{s}\atop{t}} ~~\forall ~ t \in \{0,\Nt $-$1\}$\;
          Compute principal solution $\I^{\rm sol}_s = [{\He^{\rm peak}_s}^{-1}] \I^{\rm rhs}_s$\;
          Fill solution $\I^{\rm sol}_s$ into model images $\forall t$ : $\I^{\rm m,sol}_{{s}\atop{t}}$
       }
 %     }
  %    \Else
%      {
 %      Find the location of the peak in $\vec{I}^{\rm res}_{s,0},~\forall~s\in\{0,\Ns $-$1\}$\;
 %      Construct $I^{\rm rhs}_s$, from $I^{\rm res}_{s,t}$ for the chosen $s$, at this location\;
 %      Compute $I^{sol} = [{H^{\rm peak}_s}^{-1}] I^{\rm rhs}_s$ at this location\;
 %     }
    }
       Choose $\I^{\rm m}_{{p}\atop{t}} = max\{\I^{\rm m,sol}_{{s}\atop{t=0}},~\forall~s\in\{0,\Ns $-$1\}\}$ \;
       \For{$t \in \{0,\Nt -1\}$}
       {
        Update the model image : $\I^{\rm m}_t = I^{\rm m}_t + g ~[ \I^{\rm shp}_{p} \star \I^{\rm m}_{{p}\atop{t}}]$ \;
        \For{$s \in \{0,\Ns $-$1\}$}
	{
          Update the residual image : $\I^{\rm res}_{{s}\atop{t}} = \I^{\rm res}_{{s}\atop{t}} - g ~\sum_{q=0}^{\Nt -1}[\I^{\rm psf}_{{sp}\atop{tq}} \star \I^{\rm m}_{{p}\atop{t}}]$\;
	}
       }
    }
%  \vspace{0.5cm} 
   Compute model visibilities $\V^{\rm m}_{\nu}$ from  $\I^{\rm m}_t~\forall t\in \{0.\Nt -1\}$\;
   Compute residual visibilities $\V^{\rm res}_{\nu} = \V^{\rm obs}_{\nu}-\V^{\rm m}_{\nu}$\;
  }
  \vspace{0.5cm} 
Restore the model Taylor-coefficients $\I^{\rm m}_t~\forall t\in \{0.\Nt -1\}$ \;
Calculate $\vec{I}^{\rm m}_{\nuup_0}, \vec{I}^{\rm m}_{\alphaup}, \vec{I}^{\rm m}_{\betaup}$ from $\I^{\rm m}_t~\forall t\in \{0.\Nt -1\}$\;
If required, remove average primary beam : $\vec{I}^{\rm new}_{\nuup_0}=\vec{I}^{\rm m}_{\nuup_0}/\vec{P}_{\nuup_0};  \vec{I}^{\rm new}_{\alphaup}=\vec{I}^{\rm m}_{\alphaup}-\vec{P}_{\alphaup};  \vec{I}^{\rm new}_{\betaup}=\vec{I}^{\rm m}_{\betaup}-\vec{P}_{\betaup}$\;
%\vspace{0.5cm}

  \caption[MS-MFS Algorithm]
         {MS-MFS, as implemented in CASA}\label{algo:CASA}

\end{algorithm}

\begin{algorithm}
\scriptsize
  \SetLine
  \linesnumbered
  \dontprintsemicolon
%  \SetKwRepeat{Repeat}{Repeat}{Until}
%  \SetKwFor{ForEach}{ForEach}{Do}{End}
%\KwData{ $\vec{V}^{corr}_{\nu}, \vec{I}^{\rm shp}_s~\forall~s\in\{0,\Ns $-$1\}, ~ [\Sna]~ \forall \nu$ }
%\KwResult{ $\vec{I}^{\rm psf}_{{sp}\atop{tq}},[{H^{\rm peak}_s}], \vec{I}^m_{\nu_0}, \vec{I}^{\alpha}, \vec{I}^{\beta}$ }
  \KwData{calibrated visibilities : $\vec{V}^{\rm obs}_{\nu}~~\forall \nu$}
  \KwData{$uv$-sampling function and weights : $[{\Sa}_{\nu}], [\Wimn]$}
  \KwData{input : number of Taylor-terms $\Nt $, number of scales $\Ns $}
  \KwData{input : image noise threshold, $\sigma_{\rm thr}$, loop gain $g$}
  \KwData{input : scale basis functions : $\I^{\rm shp}_s ~ \forall s\in\{0,\Ns -1\}$}
  \KwData{input : reference frequency $\nu_0$ to compute $w_{\nu}=\dnuno$}
  \KwResult{model coefficient images : $\I^{\rm m}_{t}~ \forall t\in\{0,\Nt -1\}$}
  \KwResult{intensity, spectral index and curvature : $\I^{\rm m}_{\nuup_0},\I^{\rm m}_{\alphaup},\I^{\rm m}_{\betaup}$}
 
%{Compute the dirty image $\vec{I}^{\rm dirty}$ and psf $\vec{I}^{\rm psf}$}\;
  \For{ $t \in \{0,\Nt -1\}, q \in \{t,\Nt -1\}$}
  {
{\color{red}        { Compute the spectral Hessian kernel $\vec{I}^{\rm psf}_{tq}$ from transform of frequency weight sampling } $\sum_{\nu} \wntq \Sa_{\nu}$\;}
        \For{ $s \in \{0,\Ns -1\}, p \in \{s,\Ns -1\}$}
	{
		{Compute scale-spectral kernels} $\vec{I}^{\rm psf}_{{sp}\atop{tq}} = \vec{I}^{\rm shp}_s \star \vec{I}^{\rm shp}_p \star \vec{I}^{\rm psf}_{tq} $\;
	}
  }
  \For { $s \in \{0,\Ns -1\}$}
  {
     Construct scale-dependent Taylor space Hessian $[{\He^{\rm peak}_s}]$ from $mid(\I^{\rm psf}_{{s,s}\atop{t,q}})$ and compute $[{\He^{\rm peak}_s}^{-1}]$\;
  }
%%%%%%%%%%%%%%%%%%%%%%
%%%\vspace{0.5cm}
%%  \caption[MS-MFS CLEAN : Pre-Deconvolution Setup]
%%          {MS-MFS CLEAN : Pre-Deconvolution Setup}
%%\end{algorithm}
%%%\newpage
%%
%%\begin{algorithm}[\He]
%%  \SetLine
%%  \linesnumbered
%%  \dontprintsemicolon
%%%%%%%%%%%%%%%%%%%%%%%  
%%\KwData{ $\vec{V}^{corr}_{\nu}, \vec{I}^{\rm shp}_s, \vec{I}^{\rm psf}_{{sp}\atop{tq}},[{H^{\rm peak}_s}]~~~\forall~~s \in \{0,\Ns -1\}, p \in \{s,\Ns -1\}, \sigma_{thr}$ }
%%\KwResult{$I^{\rm m}_{q}~ \forall q \in \{0,\Nt -1\}$}
%%%%%%%%%%%%%%%%%%%%%  
  Initialize the model $\vec{I}^{\rm m}_t$ for all $t \in \{0,\Nt -1\}$\; % and compute $f_{sidelobe}$ \; 
  \Repeat (\tcc*[f]{Major Cycle}) { Peak residual in $\vec{I}^{\rm res}_0 < \sigma_{\rm thr}$ }
  {
    \For{$t \in \{0,\Nt $-$1\}$}
    {
{\color{red}      Compute $\vec{I}^{\rm res}_t = \sum_{\nu} \wnt \vec{I}^{\rm res}_{\nu}$ from frequency-weighted residual visibilities $\V^{\rm res}_{\nu}$\;}
      \For{$s \in \{0,\Ns $-$1\}$}
      {
	    Convolve with $s^{th}$ scale-function $\vec{I}^{\rm res}_{{s}\atop{t}} = \vec{I}^{\rm shp}_s \star \vec{I}^{\rm res}_t$
      }
    }
    Calculate minor-cycle threshold $f_{\rm limit}$ from $\vec{I}^{\rm res}_{{0}\atop{0}}$\;
%  \vspace{0.5cm} 
    \Repeat (\tcc*[f]{Minor Cycle}){ Peak residual in $\vec{I}^{\rm res}_{{0}\atop{0}} < f_{\rm limit} $ } 
    {
%     Compute $I^{\rm m}_q~\forall q\in \{0.\Nt -1\}$ and update $\vec{I}^{\rm res}_{{s},{t}}~\forall s,t$ (Algorithm \vref{MSMFS_2})\;
     \For{$s \in \{0,\Ns $-$1\}$}
     {
%      \uIf{Peak of $\vec{I}^{\rm res}_{s,0} > 10~\sigma_{thr} $}
%      {
       \ForEach{pixel}
       {
          Construct $\I^{\rm rhs}_s$, an $\Nt \times 1$ vector from $\I^{\rm res}_{{s}\atop{t}} ~~\forall ~ t \in \{0,\Nt $-$1\}$\;
          Compute principal solution $\I^{\rm sol}_s = [{\He^{\rm peak}_s}^{-1}] \I^{\rm rhs}_s$\;
          Fill solution $\I^{\rm sol}_s$ into model images $\forall t$ : $\I^{\rm m,sol}_{{s}\atop{t}}$
       }
 %     }
  %    \Else
%      {
 %      Find the location of the peak in $\vec{I}^{\rm res}_{s,0},~\forall~s\in\{0,\Ns $-$1\}$\;
 %      Construct $I^{\rm rhs}_s$, from $I^{\rm res}_{s,t}$ for the chosen $s$, at this location\;
 %      Compute $I^{sol} = [{H^{\rm peak}_s}^{-1}] I^{\rm rhs}_s$ at this location\;
 %     }
     }
     Choose $\I^{\rm m}_{{p}\atop{t}} = max\{\I^{\rm m,sol}_{{s}\atop{t=0}},~\forall~s\in\{0,\Ns $-$1\}\}$ \;
       \For{$t \in \{0,\Nt -1\}$}
       {
        Update the model image : $\I^{\rm m}_t = I^{\rm m}_t + g ~[ \I^{\rm shp}_{p} \star \I^{\rm m}_{{p}\atop{t}}]$ \;
        \For{$s \in \{0,\Ns $-$1\}$}
	{
          Update the residual image : $\I^{\rm res}_{{s}\atop{t}} = \I^{\rm res}_{{s}\atop{t}} - g ~\sum_{q=0}^{\Nt -1}[\I^{\rm psf}_{{sp}\atop{tq}} \star \I^{\rm m}_{{p}\atop{t}}]$\;
	}
       }
    }
%  \vspace{0.5cm} 
   {\color{red} Compute model visibilities $\V^{\rm m}_{\nu}$ from  $\V^{\rm m}_t~\forall t\in \{0.\Nt -1\}$}\;
   Compute residual visibilities $\V^{\rm res}_{\nu} = \V^{\rm obs}_{\nu}-\V^{\rm m}_{\nu}$\;
  } 
Restore the model Taylor-coefficients $\I^{\rm m}_t~\forall t\in \{0.\Nt -1\}$ \;
Calculate $\vec{I}^{\rm m}_{\nuup_0}, \vec{I}^{\rm m}_{\alphaup}, \vec{I}^{\rm m}_{\betaup}$ from $\I^{\rm m}_t~\forall t\in \{0.\Nt -1\}$\;
If required, remove average primary beam : $\vec{I}^{\rm new}_{\nuup_0}=\vec{I}^{\rm m}_{\nuup_0}/\vec{P}_{\nuup_0};  \vec{I}^{\rm new}_{\alphaup}=\vec{I}^{\rm m}_{\alphaup}-\vec{P}_{\alphaup};  \vec{I}^{\rm new}_{\betaup}=\vec{I}^{\rm m}_{\betaup}-\vec{P}_{\betaup}$\;
%\vspace{0.5cm}

  \caption[MS-MFS Algorithm]
         {MS-MFS, as implemented in ASKAPsoft: {\color{red} red denotes difference from CASA}}\label{algo:ASKAP}

\end{algorithm}


\begin{figure}[htb]
  \centering
  \includegraphics[width=\textwidth]{./MSMFS_Predict_Image.pdf}
  \caption{Structure of Image plane-weighting Predict, as used in CASA. Note that the three loops (denoted by the rectangle with curved ends) can be permutated at will.}
  \label{fig:makeimageuv}
\end{figure}


\begin{figure}[htb]
  \centering
  \includegraphics[width=\textwidth]{./MSMFS_MakeImage_Image.pdf}
  \caption{Structure of Image plane-weighting MakeImage, as used in CASA. Note that the three loops (denoted by the rectangle with curved ends) can be permuted at will.}
  \label{fig:makeimageimage}
\end{figure}

The CASA and ASKAPsoft approaches should be equivalent apart from numerical differences such as due to the convolution function. Hence either can be used according to the most favourable scaling. Compared to CASA, ASKAPsoft does approximately two orders of magnitude less FFTs and 5 times as much gridding. Both forms should therefore be available in the SDP Performance Model and used as the context dictates.

The Minor Cycle is identical in CASA and ASKAPsoft. The Minor cycle is depicted graphically in Figure \ref{fig:minor}.

\begin{figure}[htb]
  \centering
  \includegraphics[width=\textwidth]{./MSMFS_Minor.pdf}
  \caption{Structure of Minor cycle for MSMFS as used in both CASA and ASKAPsoft.}
  \label{fig:minor}
\end{figure}


\clearpage
\section{Parallel processing}
\label{sec:parallel}

When moving the MSMFS algorithm to a distributed (loosely coupled) and parallel (tightly coupled) architecture such as the SDP architecture, there are a large number of important factors that must be considered.
\begin{description}
\item[Optimum partitioning] 
\item[Coupling across partitions] e.g. is the same pixel addressed in two different partitions? If so, is there a satisfactory approach to reconciling the two values? This is a generic question that should be considered for all distributed and parallel processing.
\item[Synchronisation points] e.g. is a global synchronisation point required so that the deconvolutions can be made consistent? Is there an acceptable algorithm for reconciling separate facets?
\item[Amount of CU memory]
\item[Loading of CU memory backplane] The intrinsic operations in MSMFS are mostly simple SAXBY type operations. Hence the memory backplane will be overloaded, and the CPU data-starved.
\item[Access to visibility store] What access to the visibility store is required? A straightforward implementation of the Major/Minor cycle algorithm loads the observed data every major cycle. However, as discussed in [RD15], this is actually only true of the initialisation and any self-calibration cycles. For other cycles, it is necessary only to load the uvw coordinates and flagging information.
\end{description}

\subsection{Partitioning for Predict and MakeImage}
\label{subsec:partitoningpredictmakeimage}

The SDP pipeline framework [RD04], allows partitioning across multiple axes. In this case, the natural partitions and typical values are:

\begin{description}
\item[Polarisation] Only Stokes I can be modelled using MSMFS. Modelling the Faraday Rotation is possible but there is no existing algorithm.
\item[Frequency] O(500) coarse channels are required to avoid bandwidth smearing/ There is no advantage to finer channels (see e.g. section 8.4 in [RD??]).
\item[Sub-bands] O(1-3) partitions of the coarse channels are required to ensure that the power law approximation is adequate.
\item[Time] O(43200) ~ O(1s) correlator samples are required to avoid smearing on the longest baselines
\item[Facet] O(100) facets to limit the size of the AW projection kernel
%\item[Snapshot time] O(100s) long gridding/degridding sequences are required to limit smearing due to w-plane rotation
\item[Scales] O(5) scales are typically required to model extended structure (see section 8.4 in [RD??])
\item[Taylor terms] O(5) terms are required to represent the spectral behaviour for moderately complex spectrum sources (see section 8.4 in [RD??])
\end{description}

According to the logic of the MSMFS algorithm, sub-bands can be defined as the limit of the power law approximation for brightness so consequently can always be used as the coarsest partition. For Predict and MakeImage the remaining choices are as shown in Figure \ref{tab:partitions} (most rapid first):

\begin{table}[htp]
 \caption{Possible ordering of partitions $UV$ weighting version of Predict and MakeImage}
 \label{tab:partitions}
 \begin{center}
 \begin{tabular}{|c|c|c|c|}
\hline
Frequency & Time & Facet & Sub-Band \\
Frequency & Facet & Time & Sub-Band \\
Time & Facet & Frequency & Sub-Band \\
Time & Frequency & Facet & Sub-Band \\
Facet & Time & Frequency & Sub-Band \\
Facet & Frequency & Time & Sub-Band \\
\hline
\end{tabular}
\end{center}
\end{table}

The choice is between the two orderings of Time and Facet. Since deconvolution is non-linear, we prefer that all times be represented in a single facet rather than the other way around. Hence according to this level of analysis, the best ordering is [Frequency, Time, Facet, Sub-Band]. Parallelisation over Compute Nodes starts from the left to the right, Distribution over Compute Islands works from the right to the left (see Figure \ref{fig:order}):

\begin{figure}[htb]
  \centering
  \includegraphics[width=\textwidth]{./Order.pdf}
  \caption{Preferred order of parallelisation and distribution for MakeImage and Predict sub-pipelines.}
  \label{fig:order}
\end{figure}

In this approach, the facets will almost certainly be processed on different compute islands. Note we have a dilemma on how to deal with the deconvolution of the facets.

\begin{itemize}	
\item Construct the facets with some padding, deconvolve each separately, and reconcile after deconvolution by facet to facet broadcast.
\item Construct the facets without padding, send all facets to one compute island, perform deconvolution, distribute models to facets. 
\item Each CI holds a distinct facet, which do not need to overlap. Synchronise in each minor cycle after peak finding. After a peak is found, all islands receive all peaks and choose the same global peak and update accordingly. Since the limit of coupling is assumed to be the CLEAN patch size, all peaks sufficiently far apart can be processed simultaneously.
\end{itemize}

The first approach will inevitably introduce edge effects in the final image revealing the facet grid, while the second will block processing while deconvolution proceeds on the different sub-band compute nodes. We would then benefit from two different types of nodes:
\begin{description}
\item[Predict and MakeImage] Requires the visibility data but not many scratch images. Stalls during MinorCycle.
\item[MinorCycle] Requires a substantial number of scratch images, but not the visibility data. Stalls during Predict and MakeImage.	
\end{description}

The third approach to deconvolution requires low latency communications. It should be investigated.

\subsection{Partitioning for Minor Cycle}

In the minor cycle, the first calculation is [Pixel, Taylor Term], and then the Scale convolutions are calculated. Hence the natural order overall is [Pixel, Taylor Term, Scale]. This is used in both CASA and ASKAPsoft. Both use a single threaded Minor Cycle. For SDP, a multi-threaded but not-distributed Minor Cycle should be prototyped.

However, in the minor cycle, we have a modelling problem that is not going to be wished away. The science demands seamless imaging in multiple axes, whereas computing would like to partition the image cube in those same axes. There is a tendency to assert that one axis or another does not have to be seamless but that has not be conclusively argued. Distributing the minor cycle across Compute Islands may be possible in some cases (e.g. spectral line after continuum estimation and subtraction), but we should also be considering how best to parallelise the Minor Cycle on a single, appropriately specified Compute Island.

\subsection{Implementation in CASA}

The CASA tclean program supports parallel execution using python to run copies on different nodes. This mode of parallel execution fits the CASA execution model. The visibility data are partitioned in time across the available processors. Gridding and transforms (i.e. Predict and MakeImage) are done separately and in parallel per partition. Then the Images (and weights) are gathered and then normalised. A serial minor cycle is run, blocking all other processing, and then the model image is scattered to all processes. The Major cycle is done in parallel per partition.

Thus in summary, the Major Cycles are parallelised while the deconvolution runs serially.

\subsection{Implementation in ASKAPsoft}

The ASKAPsoft code is mirrored in the SDP Github repository. The ASKAPsoft cimager is MPI-enabled, written as parallel program from the beginning/ Distribution over MPI is via frequency, rather than time as in CASA. Predict and MakeImage are distributed using MPI (via a thin bookkeeping layer). The MinorCycle is performed on the master, and thus blocks until the deconvolution steps have completed.

The minor cycle  algorithm is in C++ Template DeconvolverMultiTermBasisFunction.tcc. The basis function is abstracted and can be any class having the interface DeconvolverMultiTermBasisFunction. There are two forms present: one for point sources, and one for the same blobs used in CASA - a truncated upside down parabola. The basis functions may optionally be orthogonalised using the Gramm-Schmidt algorithm though there is little relevant experience.

The optimum blob location and scale is found by using one of two criteria:

\begin{description}
\item[MAXBASE0] The peak of term 0 across after decoupling in term.
\item[MAXCHISQ] The peak of chisquared across scale after decoupling in term.
\end{description}

The second criterion is expensive to compute and usually MAXBASE0 is used. Thus for each scale and for each pixel the pixel value at the reference frequency has to be determined by pre-multiplying by the inverse Hessian (in term-term space). This means that the cost of the search is:

\begin{equation}
Rflop_{MSMFSminor} = N_{minor} N_{pix}^2 N_s N_T	
\end{equation}


To save on calculation, a number of cached images are used. For ASKAPsoft, these are shown in Table \ref{tab:askapmemory}.

\begin{table}[tbh]
\caption{ASKAPsoft cimager use of memory during minor cycles}\label{tab:askapmemory}

\begin{tabular}{|l|c|c|c|}
\hline
Item & Axes & Size (words) & Needed? \\
\hline
Basis function FFT & scales & $N_{pix}^2 N_S $ & During initialisation \\
PSF FFT & 2 * Taylor terms & $2 N_{pix}^2 N_T $ & During initialisation \\
Spectral Dirty image & Taylor terms, scales & $N_{pix}^2 N_T N_s$ & During iteration \\
Spectral Dirty PSF & Taylor terms, scales & $N_{patch}^2 N_T N_s$ & During iteration \\
Spectral Model image & Taylor terms & $N_{pix}^2 N_T $ & During iteration \\	
Basis functions & scales & $N_{pix}^2 N_s$ & During iteration \\
Inverse of Hessian & Taylor terms, Taylor terms, scales & $N^2_T N_s$ & During Iteration \\
\hline
\end{tabular}	
\end{table}

where $N_{pix}$ is the number of pixels on an axis of the image, $N_{patch}$ is the number of pixels in the patch of the Dirty beam used, $N_T$ is the number of Taylor terms, and $N_S$ is the number of scales/basis functions.

Thus, keeping only the dominant terms, the total memory used during iteration is: 

\begin{equation}
M_{MSMFS} = (N_T (N_s + 1) + N_s) N_{pix}^2 
\end{equation}

Using L2 assumptions values of $N_t=5$ and $N_s=10$, we find that the memory use is about $65 N_{pix}$. For a 200,000 by 200,000 pixel image, this requires 10.4 TB total. Spread over O(100) Compute Islands (partitioning by facet and sub-band), this requires 104 GB per CI. The overhead for performing the MSMFS minor cycle is a factor of fifty, and for the major cycle a factor of 5 (if ASKAP) in gridding, and a factor of O(500) in FFT (if CASA).


%
%\clearpage
%\section{A projection}
%\label{sec:minor}
%
%\clearpage
%\section{Wide-band behaviour}
%\label{sec:wideband}
%
%\begin{itemize}
%\item Does naive broadband work?
%\item Bhatnagar et al WB algorithm	
%\end{itemize}
%

\clearpage
\section{Other considerations}
\label{sec:other}

Ignoring the behaviour of the MSMFS algorithm, there are other considerations arising from the use of any MFS technique (this discussion drawn from section 8.4 of [RD07]).

\begin{description}
\item[Calibration]	
The use of MSMFS or any technique taking advantage of simple models of broadband behaviour requires that the calibration across the observing band be well understood. Otherwise errors in bandpass calibration will couple into derived spatial structure. Hence there is a derived system requirement on bandpass accuracy, even just for continuum imaging. This should be evaluated via simulations and analysis.
\item[Anomalous spectral index objects] such as some pulsars, GHz-peaked sources, very extended radio galaxies, may limit dynamic range.
\item[Primary beam model] If the true spectrum is to be recovered, the primary beam must be modelled accurately.
\item[UV coverage effects] The fine structure is constrained by the high frequency measurements and the extended emission is constrained by the low frequency measurements. In principle, these biases can be avoided by limiting the range of uv coordinates to a common set at all frequencies, but this does somewhat defeat the purpose of MFS. It is not clear how serious this effect will be for SKA.
\end{description}

In addition, Bhatnagar et al. [RD18] have drawn attention to the difficulties of performing primary beam correction over a wide bandwidth. They note some difficulties with the straightforward application of what they call the Narrow Band MSMFS algorithm (which we call simply MSMFS) to large bandwidths. Specifically the apparent Noise to Signal Ratio becomes very large outside the primary beam. They argue that analysis of the images scientifically relies upon understanding the noise level outside the primary beam sampled area. This is undoubtedly correct, and MIRIAD and ASKAPsoft address this by designating a primary beam cutoff beyond which the noise alone is used without normalisation. In their approach, Bhatnagar et al. advocate correcting the primary beam to a desired effective primary beam. This is quite sensible. Some evaluation of this approach should be performed using simulations, and the scientific analysis implications should be considered.

\clearpage
\section{Recommendations}
\label{sec:recommendations}

Parallel versions of both variants of MSMFS exist. These work by distributing in time (CASA) and frequency (ASKAPsoft). Parallelisation of the Minor Cycle is not straightforward and consequently both CASA and ASKAPsoft currently use single-threaded inner loops. This is unlikely to be successful for SKA, and instead the Minor Cycle has to be parallelised inside one CI and perhaps additionally distributed over multiple CI's.

In light of this memo, the following recommendations are made concerning the need for MFS:

\begin{enumerate}
\item Perform simulations to explore the need for MSMFS in SKA. Currently an L1 requirement directs SDP to implement MSMFS. However there is no justification given for this very computationally demanding processing. Indeed the promised excellent UV coverage of the SKA telescopes makes it at least questionable, although arguing from the work of Urvashi [RD??] does indicate that with MFS, the dynamic range would be limited to $10^4$ for wide frequency span. Either CASA or ASKAPsoft could be used for the reconstructions.
\item Adding to the desire to see some more justification of the requirement, we note that the L1 requirements do not address the number of scales required, the number of Taylor terms, or the possibility of sub-banding (all of which appear in the SDP L2 requirements. We note three possible outcomes of the simulations: MFS can be ignored, MFS is required and MSMFS is sufficient, or MFS is needed and MFMFS is not sufficient. In the case of the latter outcome, investigation of other deconvolution techniques (e.g. [RD14]) would be required.
\item Assess the importance of the considerations in Section \ref{sec:other}.
\end{enumerate}

The following recommendations address the resource usage:
\begin{enumerate}[resume]
\item Implement both Image (CASA) and Visibility based (ASKAPsoft) calculation of the Taylor term images in the SDP Performance Model. The main reasons to choose one over the other are to do with the relative speed of gridding and FFTs. When it comes to implementation during construction, the costs of implementing both approaches should be minimal, and unimportant compared to the risk of implementing the wrong choice.
\item Update the SDP Performance Model to reflect the MSMFS memory usage:
\begin{equation}
M_{MSMFS} = (N_T (N_s + 1) + N_s) N_{pix}^2 
\end{equation}
\item Update the SDP Performance Model to reflect the MSMFS Flops:
\begin{equation}
Rflop_{MSMFSminor} = N_{minor} N_{pix}^2 N_s N_T	
\end{equation}
\item Prototype a multi-threaded Minor Cycle on one Compute Island. GPUMultiscaleCLEAN might be a good starting point. Do MS and then MSMFS. This can be done without implementing a major cycle.
\item Model and then, if promising, prototype a distributed Minor Cycle on multiple CI's where synchronisation occurs every iteration. Do MS and then MSMFS. This can be done without implementing a major cycle.\end{enumerate}

The following recommendations address wider issues:
\begin{enumerate}[resume]
\item The SKAO Science Team should be consulted about the impact of seams in the images or spectral cubes. These may occur both spatially (if the facets are deconvolved separately, or in frequency, because of the disjoint use of MSMFS in the different sub-bands. It seems questionable that these can be tolerated.

\item We should note that MSMFS was developed in a serial platform where computation was expensive and memory access cheap. In the SDP context, the processing is distributed and parallel, and computation is cheap and memory access expensive. Although SDP has no remit to develop new algorithms, it could encourage researchers to address this new context.
\end{enumerate}


% \label{section:main}



% Add the bibliography
\clearpage \addcontentsline{toc}{section}{References}
\bibliography{your_bibfile}%



\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
